# ðŸ”§ Technical Specifications & Deployment Guide

## System Requirements

### Development Environment

#### Minimum Requirements
- **Operating System**: Windows 10+, macOS 10.14+, or Ubuntu 18.04+
- **Node.js**: Version 18.0+ (LTS recommended)
- **MongoDB**: Version 6.0+
- **Browser**: Chrome 90+, Firefox 88+, Safari 14+, Edge 90+
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: 10GB free space for development
- **Internet**: Stable broadband connection (10 Mbps+)

#### Recommended Development Setup
- **IDE**: Visual Studio Code with extensions:
  - ES7+ React/Redux/React-Native snippets
  - Prettier - Code formatter
  - ESLint
  - Thunder Client (API testing)
  - MongoDB for VS Code
- **Node Version Manager**: nvm for managing Node.js versions
- **Database Tool**: MongoDB Compass for database management
- **API Testing**: Postman or Thunder Client

### Production Environment

#### Server Requirements
- **CPU**: Multi-core processor, 2.4GHz+ (4+ cores recommended)
- **RAM**: 16GB minimum, 32GB recommended for high traffic
- **Storage**: SSD with 100GB+ available space
- **Network**: High-speed internet with static IP
- **Operating System**: Ubuntu 20.04 LTS or CentOS 8+

#### Cloud Platform Recommendations
- **AWS**: EC2 instances (t3.large or larger)
- **Google Cloud**: Compute Engine (n1-standard-2 or larger)
- **Azure**: Virtual Machines (Standard_B2s or larger)
- **DigitalOcean**: Droplets (4GB RAM, 2 vCPUs or larger)

## Security Configuration

### Authentication & Authorization

#### JWT Configuration
```javascript
// Security settings for JWT tokens
const jwtConfig = {
  secret: process.env.JWT_SECRET, // 256-bit random string
  expiresIn: '24h', // Token expiration
  issuer: 'excel-analytics-platform',
  audience: 'platform-users',
  algorithm: 'HS256'
};

// Password requirements
const passwordPolicy = {
  minLength: 8,
  requireUppercase: true,
  requireLowercase: true,
  requireNumbers: true,
  requireSpecialChars: false,
  maxAttempts: 5,
  lockoutDuration: '15m'
};
```

#### Security Headers
```javascript
// Helmet.js security configuration
app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      styleSrc: ["'self'", "'unsafe-inline'", "fonts.googleapis.com"],
      fontSrc: ["'self'", "fonts.gstatic.com"],
      scriptSrc: ["'self'"],
      imgSrc: ["'self'", "data:", "https:"],
      connectSrc: ["'self'"]
    }
  },
  hsts: {
    maxAge: 31536000,
    includeSubDomains: true,
    preload: true
  }
}));
```

### Data Protection

#### Encryption Standards
- **Data in Transit**: TLS 1.3 encryption for all HTTP communications
- **Data at Rest**: AES-256 encryption for sensitive database fields
- **File Storage**: Encrypted file uploads with secure key management
- **Backup Encryption**: AES-256 encryption for all backup data

#### Privacy Compliance
```javascript
// GDPR compliance configuration
const privacyConfig = {
  dataRetention: {
    userActivity: '2 years',
    uploadedFiles: '5 years',
    chartHistory: '3 years',
    systemLogs: '1 year'
  },
  anonymization: {
    enableAnonymization: true,
    scheduleCleanup: 'monthly',
    anonymizeAfter: '6 months inactive'
  },
  userRights: {
    dataExport: true,
    dataCorrection: true,
    dataDeletion: true,
    dataPortability: true
  }
};
```

## Database Configuration

### MongoDB Setup

#### Production Database Configuration
```javascript
// MongoDB connection for production
const mongoConfig = {
  uri: process.env.MONGODB_URI,
  options: {
    useNewUrlParser: true,
    useUnifiedTopology: true,
    maxPoolSize: 50,
    minPoolSize: 5,
    maxIdleTimeMS: 30000,
    serverSelectionTimeoutMS: 5000,
    socketTimeoutMS: 45000,
    bufferMaxEntries: 0,
    retryWrites: true,
    w: 'majority'
  }
};
```

#### Database Optimization
```javascript
// Index creation for performance
db.users.createIndex({ email: 1 }, { unique: true });
db.users.createIndex({ role: 1, isActive: 1 });
db.chartHistory.createIndex({ user: 1, createdAt: -1 });
db.chartHistory.createIndex({ chartType: 1, createdAt: -1 });
db.uploadedFiles.createIndex({ user: 1, uploadedAt: -1 });
db.uploadedFiles.createIndex({ user: 1, isActive: 1 });
db.activities.createIndex({ user: 1, timestamp: -1 });
db.activities.createIndex({ type: 1, timestamp: -1 });
db.userActivity.createIndex({ user: 1, timestamp: -1 });
db.notifications.createIndex({ user: 1, isRead: 1, createdAt: -1 });
```

#### Backup Strategy
```bash
#!/bin/bash
# Automated backup script
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/mongodb"
DB_NAME="excel_analytics"

# Create backup
mongodump --uri="$MONGODB_URI" --db="$DB_NAME" --out="$BACKUP_DIR/$DATE"

# Compress backup
tar -czf "$BACKUP_DIR/backup_$DATE.tar.gz" -C "$BACKUP_DIR" "$DATE"

# Upload to cloud storage (AWS S3 example)
aws s3 cp "$BACKUP_DIR/backup_$DATE.tar.gz" s3://your-backup-bucket/mongodb/

# Clean up local backups older than 7 days
find "$BACKUP_DIR" -name "*.tar.gz" -mtime +7 -delete
```

## Environment Configuration

### Development Environment Variables
```bash
# Backend (.env)
NODE_ENV=development
PORT=5000
MONGODB_URI=mongodb://localhost:27017/excel_analytics_dev
JWT_SECRET=your-super-secure-jwt-secret-key-min-32-chars
JWT_EXPIRE=24h

# Email Configuration
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_USER=your-email@gmail.com
EMAIL_PASS=your-app-password
EMAIL_FROM=Excel Analytics Platform <noreply@yourplatform.com>

# File Upload
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=52428800
ALLOWED_FILE_TYPES=.xlsx,.xls,.csv

# Security
BCRYPT_ROUNDS=12
RATE_LIMIT_WINDOW=15
RATE_LIMIT_MAX=100
CORS_ORIGIN=http://localhost:3000

# Performance
ENABLE_COMPRESSION=true
ENABLE_CACHING=true
CACHE_TTL=300
```

### Production Environment Variables
```bash
# Backend Production (.env)
NODE_ENV=production
PORT=5000
MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/excel_analytics
JWT_SECRET=production-super-secure-jwt-secret-key-min-64-chars
JWT_EXPIRE=24h

# SSL Configuration
SSL_CERT_PATH=/etc/ssl/certs/domain.crt
SSL_KEY_PATH=/etc/ssl/private/domain.key
FORCE_HTTPS=true

# Email Production
EMAIL_HOST=smtp.sendgrid.net
EMAIL_PORT=587
EMAIL_USER=apikey
EMAIL_PASS=your-sendgrid-api-key

# Performance Production
NODE_OPTIONS=--max-old-space-size=4096
UV_THREADPOOL_SIZE=128
ENABLE_CLUSTERING=true
CLUSTER_WORKERS=auto

# Monitoring
LOG_LEVEL=info
LOG_FILE=/var/log/excel-analytics/app.log
ENABLE_METRICS=true
METRICS_PORT=9090
```

### Frontend Environment Variables
```bash
# Frontend Development (.env)
VITE_API_URL=http://localhost:5000/api
VITE_APP_NAME=Excel Analytics Platform
VITE_APP_VERSION=1.0.0
VITE_MAX_FILE_SIZE=52428800
VITE_SUPPORTED_FORMATS=.xlsx,.xls,.csv
VITE_ENABLE_3D_CHARTS=true
VITE_ENABLE_ANALYTICS=true

# Frontend Production (.env.production)
VITE_API_URL=https://api.yourplatform.com/api
VITE_APP_NAME=Excel Analytics Platform
VITE_APP_VERSION=1.0.0
VITE_ENABLE_PWA=true
VITE_ENABLE_OFFLINE_MODE=true
```

## Deployment Strategies

### Docker Deployment

#### Multi-Stage Dockerfile (Backend)
```dockerfile
# Backend Dockerfile
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

FROM node:18-alpine AS dev
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
EXPOSE 5000
CMD ["npm", "run", "dev"]

FROM base AS production
COPY . .
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001
USER nodejs
EXPOSE 5000
CMD ["npm", "start"]
```

#### Frontend Dockerfile
```dockerfile
FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM nginx:alpine AS production
COPY --from=build /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf
RUN addgroup -g 1001 -S nginx
RUN adduser -S nginx -u 1001 -G nginx
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

#### Docker Compose (Production)
```yaml
version: '3.8'

services:
  mongodb:
    image: mongo:6.0
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASS}
      MONGO_INITDB_DATABASE: excel_analytics
    volumes:
      - mongodb_data:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - app-network
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    build:
      context: ./backend
      target: production
    restart: unless-stopped
    environment:
      NODE_ENV: production
      MONGODB_URI: mongodb://${MONGO_ROOT_USER}:${MONGO_ROOT_PASS}@mongodb:27017/excel_analytics?authSource=admin
      JWT_SECRET: ${JWT_SECRET}
    volumes:
      - uploads_data:/app/uploads
      - logs_data:/var/log/excel-analytics
    networks:
      - app-network
    depends_on:
      mongodb:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build:
      context: ./frontend
      target: production
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./ssl:/etc/nginx/ssl:ro
    networks:
      - app-network
    depends_on:
      backend:
        condition: service_healthy

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis_data:/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  mongodb_data:
  uploads_data:
  logs_data:
  redis_data:

networks:
  app-network:
    driver: bridge
```

### Cloud Deployment

#### AWS Deployment (Terraform)
```hcl
# AWS infrastructure configuration
provider "aws" {
  region = var.aws_region
}

# VPC Configuration
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "excel-analytics-vpc"
  }
}

# Application Load Balancer
resource "aws_lb" "main" {
  name               = "excel-analytics-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets           = aws_subnet.public[*].id

  enable_deletion_protection = false

  tags = {
    Environment = var.environment
  }
}

# ECS Cluster
resource "aws_ecs_cluster" "main" {
  name = "excel-analytics-cluster"

  setting {
    name  = "containerInsights"
    value = "enabled"
  }
}

# RDS Database
resource "aws_db_instance" "mongodb" {
  identifier     = "excel-analytics-db"
  engine         = "mongodb"
  engine_version = "6.0"
  instance_class = "db.t3.medium"
  
  allocated_storage     = 100
  max_allocated_storage = 1000
  storage_encrypted     = true
  
  db_name  = "excel_analytics"
  username = var.db_username
  password = var.db_password
  
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"
  
  skip_final_snapshot = false
  final_snapshot_identifier = "excel-analytics-final-snapshot"
  
  tags = {
    Environment = var.environment
  }
}
```

#### Kubernetes Deployment
```yaml
# Kubernetes deployment configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: excel-analytics-backend
  labels:
    app: excel-analytics-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: excel-analytics-backend
  template:
    metadata:
      labels:
        app: excel-analytics-backend
    spec:
      containers:
      - name: backend
        image: your-registry/excel-analytics-backend:latest
        ports:
        - containerPort: 5000
        env:
        - name: NODE_ENV
          value: "production"
        - name: MONGODB_URI
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: mongodb-uri
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: jwt-secret
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 5000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 5000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: excel-analytics-backend-service
spec:
  selector:
    app: excel-analytics-backend
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
  type: ClusterIP
```

## Performance Optimization

### Backend Optimization

#### Node.js Performance Tuning
```javascript
// Cluster configuration for production
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  console.log(`Master ${process.pid} is running`);

  // Fork workers
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died`);
    cluster.fork();
  });
} else {
  // Worker process
  require('./server.js');
  console.log(`Worker ${process.pid} started`);
}
```

#### Caching Strategy
```javascript
// Redis caching implementation
const redis = require('redis');
const client = redis.createClient({
  host: process.env.REDIS_HOST,
  port: process.env.REDIS_PORT,
  password: process.env.REDIS_PASSWORD
});

// Cache middleware
const cacheMiddleware = (duration = 300) => {
  return async (req, res, next) => {
    const key = `cache:${req.originalUrl}`;
    
    try {
      const cached = await client.get(key);
      if (cached) {
        return res.json(JSON.parse(cached));
      }
      
      res.sendResponse = res.json;
      res.json = (body) => {
        client.setex(key, duration, JSON.stringify(body));
        res.sendResponse(body);
      };
      
      next();
    } catch (error) {
      next();
    }
  };
};
```

### Database Optimization

#### Connection Pooling
```javascript
// MongoDB connection pooling
const mongoose = require('mongoose');

const connectDB = async () => {
  try {
    const conn = await mongoose.connect(process.env.MONGODB_URI, {
      useNewUrlParser: true,
      useUnifiedTopology: true,
      maxPoolSize: 50,
      minPoolSize: 5,
      maxIdleTimeMS: 30000,
      serverSelectionTimeoutMS: 5000,
      socketTimeoutMS: 45000,
      bufferMaxEntries: 0,
      retryWrites: true,
      w: 'majority'
    });

    console.log(`MongoDB Connected: ${conn.connection.host}`);
  } catch (error) {
    console.error(error);
    process.exit(1);
  }
};
```

#### Query Optimization
```javascript
// Aggregation pipeline optimization
const getAnalytics = async (userId, timeRange) => {
  return await ChartHistory.aggregate([
    {
      $match: {
        user: mongoose.Types.ObjectId(userId),
        createdAt: {
          $gte: new Date(Date.now() - timeRange * 24 * 60 * 60 * 1000)
        }
      }
    },
    {
      $group: {
        _id: {
          type: '$chartType',
          date: {
            $dateToString: {
              format: '%Y-%m-%d',
              date: '$createdAt'
            }
          }
        },
        count: { $sum: 1 }
      }
    },
    {
      $sort: { '_id.date': 1 }
    }
  ]);
};
```

### Frontend Optimization

#### Code Splitting
```javascript
// React lazy loading and code splitting
import { lazy, Suspense } from 'react';

const Dashboard = lazy(() => import('./pages/Dashboard/Dashboard'));
const Charts = lazy(() => import('./pages/Charts/Charts'));
const Admin = lazy(() => import('./pages/Admin/Admin'));

function App() {
  return (
    <Suspense fallback={<div>Loading...</div>}>
      <Routes>
        <Route path="/dashboard" element={<Dashboard />} />
        <Route path="/charts" element={<Charts />} />
        <Route path="/admin" element={<Admin />} />
      </Routes>
    </Suspense>
  );
}
```

#### Bundle Analysis
```javascript
// Vite bundle analysis configuration
export default defineConfig({
  build: {
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['react', 'react-dom'],
          charts: ['recharts', 'plotly.js', 'three'],
          ui: ['framer-motion', '@headlessui/react'],
          utils: ['axios', 'lodash']
        }
      }
    },
    sourcemap: false,
    minify: 'terser',
    terserOptions: {
      compress: {
        drop_console: true,
        drop_debugger: true
      }
    }
  }
});
```

## Monitoring and Logging

### Application Monitoring
```javascript
// Health check endpoint
app.get('/health', (req, res) => {
  const health = {
    uptime: process.uptime(),
    message: 'OK',
    timestamp: Date.now(),
    checks: {
      database: 'connected',
      redis: 'connected',
      memory: process.memoryUsage(),
      cpu: process.cpuUsage()
    }
  };
  
  res.status(200).json(health);
});

// Metrics collection
const promClient = require('prom-client');
const collectDefaultMetrics = promClient.collectDefaultMetrics;
collectDefaultMetrics();

const httpRequestDuration = new promClient.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code']
});
```

### Logging Configuration
```javascript
// Winston logger setup
const winston = require('winston');

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'excel-analytics' },
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' }),
    new winston.transports.Console({
      format: winston.format.simple()
    })
  ]
});
```

## Backup and Recovery

### Automated Backup System
```bash
#!/bin/bash
# Comprehensive backup script

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_ROOT="/backups"
APP_ROOT="/app"

# Database backup
echo "Starting MongoDB backup..."
mongodump --uri="$MONGODB_URI" --out="$BACKUP_ROOT/db_$TIMESTAMP"

# Application files backup
echo "Backing up application files..."
tar -czf "$BACKUP_ROOT/app_$TIMESTAMP.tar.gz" \
  --exclude="node_modules" \
  --exclude="logs" \
  --exclude="tmp" \
  "$APP_ROOT"

# Upload files backup
echo "Backing up uploaded files..."
tar -czf "$BACKUP_ROOT/uploads_$TIMESTAMP.tar.gz" "$APP_ROOT/uploads"

# Configuration backup
echo "Backing up configuration..."
cp /etc/nginx/nginx.conf "$BACKUP_ROOT/nginx_$TIMESTAMP.conf"
cp "$APP_ROOT/.env" "$BACKUP_ROOT/env_$TIMESTAMP"

# Upload to cloud storage
echo "Uploading to cloud storage..."
aws s3 sync "$BACKUP_ROOT" s3://your-backup-bucket/backups/

# Cleanup old backups
echo "Cleaning up old backups..."
find "$BACKUP_ROOT" -name "*" -mtime +30 -delete

echo "Backup completed successfully!"
```

### Disaster Recovery Plan
```bash
#!/bin/bash
# Disaster recovery script

BACKUP_DATE=$1
BACKUP_ROOT="/backups"
APP_ROOT="/app"

if [ -z "$BACKUP_DATE" ]; then
  echo "Usage: $0 <backup_date>"
  exit 1
fi

echo "Starting disaster recovery for backup: $BACKUP_DATE"

# Stop services
echo "Stopping services..."
docker-compose down

# Restore database
echo "Restoring database..."
mongorestore --uri="$MONGODB_URI" --drop "$BACKUP_ROOT/db_$BACKUP_DATE"

# Restore application files
echo "Restoring application files..."
tar -xzf "$BACKUP_ROOT/app_$BACKUP_DATE.tar.gz" -C /

# Restore uploads
echo "Restoring uploaded files..."
tar -xzf "$BACKUP_ROOT/uploads_$BACKUP_DATE.tar.gz" -C "$APP_ROOT"

# Restore configuration
echo "Restoring configuration..."
cp "$BACKUP_ROOT/nginx_$BACKUP_DATE.conf" /etc/nginx/nginx.conf
cp "$BACKUP_ROOT/env_$BACKUP_DATE" "$APP_ROOT/.env"

# Start services
echo "Starting services..."
docker-compose up -d

echo "Disaster recovery completed successfully!"
```

## Troubleshooting Guide

### Common Production Issues

#### High Memory Usage
```bash
# Monitor memory usage
free -h
ps aux --sort=-%mem | head

# Node.js memory optimization
export NODE_OPTIONS="--max-old-space-size=4096"

# MongoDB memory optimization
# Add to /etc/mongod.conf
storage:
  wiredTiger:
    engineConfig:
      cacheSizeGB: 2
```

#### Database Connection Issues
```javascript
// Connection retry logic
const connectWithRetry = () => {
  mongoose.connect(process.env.MONGODB_URI, {
    useNewUrlParser: true,
    useUnifiedTopology: true
  }).then(() => {
    console.log('MongoDB connected successfully');
  }).catch(err => {
    console.error('Failed to connect to MongoDB:', err);
    console.log('Retrying connection in 5 seconds...');
    setTimeout(connectWithRetry, 5000);
  });
};
```

#### Performance Bottlenecks
```javascript
// Performance monitoring middleware
const performanceMonitor = (req, res, next) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - start;
    if (duration > 1000) {
      console.warn(`Slow request: ${req.method} ${req.path} - ${duration}ms`);
    }
  });
  
  next();
};
```

This technical specification provides comprehensive guidance for deploying and maintaining the Excel Analytics Platform in production environments, ensuring security, performance, and reliability.

---

*Last updated: October 2, 2025 - Excel Analytics Platform Technical Specifications v1.0*